{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658dd0e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4d1003d",
   "metadata": {},
   "source": [
    "Optionally, we may specify the mode of imread. The supported options include the following:\n",
    "\n",
    "\n",
    "cv2.IMREAD_COLOR: This is the default option, providing a 3-channel BGR image with an 8-bit value (0-255) for each channel.\n",
    "cv2.IMREAD_GRAYSCALE: This provides an 8-bit grayscale image.\n",
    "cv2.IMREAD_ANYCOLOR: This provides either an 8-bit-per-channel BGR image or an 8-bit grayscale image, depending on the metadata in the file.\n",
    "cv2.IMREAD_UNCHANGED: This reads all of the image data, including the alpha or transparency channel (if there is one) as a fourth channel.\n",
    "cv2.IMREAD_ANYDEPTH: This loads an image in grayscale at its original bit depth. For example, it provides a 16-bit-per-channel grayscale image if the file represents an image in this format.\n",
    "cv2.IMREAD_ANYDEPTH | cv2.IMREAD_COLOR: This combination loads an image in BGR color at its original bit depth.\n",
    "cv2.IMREAD_REDUCED_GRAYSCALE_2: This loads an image in grayscale at half its original resolution. For example, if the file contains a 640 x 480 image, it is loaded as a 320 x 240 image.\n",
    "cv2.IMREAD_REDUCED_COLOR_2: This loads an image in 8-bit-per-channel BGR color at half its original resolution.\n",
    "cv2.IMREAD_REDUCED_GRAYSCALE_4: This loads an image in grayscale at one-quarter of its original resolution.\n",
    "cv2.IMREAD_REDUCED_COLOR_4: This loads an image in 8-bit-per-channel color at one-quarter of its original resolution.\n",
    "cv2.IMREAD_REDUCED_GRAYSCALE_8: This loads an image in grayscale at one-eighth of its original resolution.\n",
    "cv2.IMREAD_REDUCED_COLOR_8: This loads an image in 8-bit-per-channel color at one-eighth of its original resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ebf84",
   "metadata": {},
   "source": [
    "##    LECTURA Y ESCRITURA DE IMAGENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb269b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import sys\n",
    "\n",
    "img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\") )\n",
    "\n",
    "if img is None:\n",
    "    sys.exit(\"No se puede mostrar el archivo\")\n",
    "    \n",
    "cv.imshow(\"Ventana de muestra\", img)\n",
    "k = cv.waitKey(0)\n",
    "\n",
    "if k == ord(\"s\"):\n",
    "    cv.imwrite(\"sources/salida de imagen.png\", img)\n",
    "elif k == ord(\"q\"):\n",
    "    cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3276766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "(136, 240, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import sys\n",
    "\n",
    "#img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_COLOR)\n",
    "#img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_GRAYSCALE)\n",
    "#img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_UNCHANGED )\n",
    "#img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_ANYDEPTH )\n",
    "#img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_ANYDEPTH | cv.IMREAD_COLOR )\n",
    "#img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_REDUCED_GRAYSCALE_2 )\n",
    "#img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_REDUCED_COLOR_2 )\n",
    "#img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_REDUCED_GRAYSCALE_4 )\n",
    "#img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_REDUCED_COLOR_4 )\n",
    "#img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_REDUCED_GRAYSCALE_8 )\n",
    "img = cv.imread(cv.samples.findFile(\"sources/emblema.jpg\"), cv.IMREAD_REDUCED_COLOR_8 )\n",
    "\n",
    "\n",
    "if img is None:\n",
    "    sys.exit(\"No se puede mostrar el archivo\")\n",
    "    \n",
    "cv.imshow(\"Ventana de muestra\", img)\n",
    "k = cv.waitKey(0)\n",
    "\n",
    "if k == ord(\"s\"):\n",
    "    cv.imwrite(\"sources/salida de imagen.png\", img)\n",
    "elif k == ord(\"q\"):\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "print (img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e4b49",
   "metadata": {},
   "source": [
    "As an example, let's load a PNG file as a grayscale image (losing any color information in the process), and then save it as a grayscale PNG image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "139a99a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "(200, 146, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import sys\n",
    "\n",
    "#grayImage = cv.imread('sources/goku.png', cv.IMREAD_GRAYSCALE)\n",
    "grayImage = cv.imread('sources/goku.png', cv.IMREAD_REDUCED_COLOR_8)\n",
    "\n",
    "if grayImage is None:\n",
    "    print('Failed to read image from file')\n",
    "    sys.exit(1)\n",
    "success = cv.imwrite('sources/gokuOut.png', grayImage)\n",
    "if not success:\n",
    "    print('Failed to write image to file')\n",
    "    sys.exit(1)\n",
    "    \n",
    "print (grayImage)\n",
    "print(grayImage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55950849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fa25646",
   "metadata": {},
   "source": [
    "## Video\n",
    "### captura de video camara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34f5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture(2)\n",
    "if not cap.isOpened():\n",
    "    print(\"No es posible abrir la camara\")\n",
    "    exit()\n",
    "    \n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"No se puede recibir datos (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    # Our operations on the frame come here\n",
    "    #gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    #cv.imshow('mostrador Video', gray)\n",
    "    \n",
    "    \n",
    "    cv.imshow('mostrador Video', frame)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3462b1d5",
   "metadata": {},
   "source": [
    "### Leyendo video\n",
    "\n",
    "Antes de instalar asegurarse de la version de ffmpeg o gstreamer esté instalado previamente, algunas veces arroga error por este tipo de dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c013e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#import cv2 as cv\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msources/flores.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m      5\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import cv2 as cv\n",
    "cap = cv.VideoCapture('sources/flores.mp4')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc553d98",
   "metadata": {},
   "source": [
    "### Guardando video\n",
    "\n",
    "Antes de instalar asegurarse de la version de ffmpeg o gstreamer esté instalado previamente, algunas veces arroga error por este tipo de dependencias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518e30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import cv2 as cv\n",
    "cap = cv.VideoCapture(2)\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "out = cv.VideoWriter('sources/output.mp4', fourcc, 20.0, (3840,  2160))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    frame = cv.flip(frame, 0)\n",
    "    # write the flipped frame\n",
    "    out.write(frame)\n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f08da7",
   "metadata": {},
   "source": [
    "# Guardar video\n",
    "\n",
    "* 0: Esta opción es un archivo de vídeo sin comprimir. La extensión del archivo debe ser ..avi\n",
    "* cv2.VideoWriter_fourcc('I','4','2','0'): Esta opción es una codificación YUV sin comprimir, submuestreo de croma 4:2:0. Esta codificación es ampliamente compatible, pero produce archivos grandes. La extensión del archivo debe ser ..avi\n",
    "* cv2.VideoWriter_fourcc('P','I','M','1'): Esta opción es MPEG-1. La extensión del archivo debe ser ..avi\n",
    "* cv2.VideoWriter_fourcc('X','V','I','D'): Esta opción es una codificación MPEG-4 relativamente antigua. Es una buena opción si desea limitar el tamaño del video resultante. La extensión del archivo debe ser ..avi\n",
    "* cv2.VideoWriter_fourcc('M','P','4','V'): Esta opción es otra codificación MPEG-4 relativamente antigua. Es una buena opción si desea limitar el tamaño del video resultante. La extensión del archivo debe ser ..mp4\n",
    "* cv2.VideoWriter_fourcc('X','2','6','4'): Esta opción es una codificación MPEG-4 relativamente nueva. Puede ser la mejor opción si desea limitar el tamaño del video resultante. La extensión del archivo debe ser ..mp4\n",
    "* cv2.VideoWriter_fourcc('T','H','E','O'): Esta opción es Ogg Vorbis. La extensión del archivo debe ser .ogv\n",
    "\n",
    "También se debe especificar una velocidad de fotogramas y un tamaño de fotograma. Como estamos copiando de otro video, estas propiedades se pueden leer desde el método get de la clase.VideoCapture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ec6911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0\n",
      "(1920, 1080)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "videoCapture = cv2.VideoCapture('sources/flores.mp4')\n",
    "fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
    "print (fps)\n",
    "\n",
    "size = (int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "print(size)\n",
    "\n",
    "\n",
    "videoWriter = cv2.VideoWriter(\n",
    "    'sources/MyOutputVid.avi', cv2.VideoWriter_fourcc('I','4','2','0'),\n",
    "    fps, size)\n",
    "\n",
    "success, frame = videoCapture.read()\n",
    "while success:  # Loop until there are no more frames.\n",
    "    videoWriter.write(frame)\n",
    "    success, frame = videoCapture.read()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f9e7b",
   "metadata": {},
   "source": [
    "\n",
    "## Enabling hardware acceleration for video I/O\n",
    "\n",
    "A menudo, las GPU modernas son capaces de acelerar los algoritmos que decodifican (leen) y codifican (escriben) algunos de los formatos de video comunes. De forma predeterminada, OpenCV y clases no intentan usar la aceleración de GPU; ejecutan los algoritmos de decodificación y codificación en la CPU. Sin embargo, a partir de OpenCV 4.5.2 y continuando en OpenCV 5, el soporte para la codificación/decodificación acelerada por GPU ha ido mejorando. Si modificamos nuestro ejemplo de E/S de vídeo de las formas resaltadas a continuación, OpenCV intentará utilizar la aceleración de GPU en sistemas compatibles:VideoCaptureVideoWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59d33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "videoCapture = cv2.VideoCapture(\n",
    "    'sources/output.mp4', cv2.CAP_ANY,\n",
    "    [cv2.CAP_PROP_HW_ACCELERATION, cv2.VIDEO_ACCELERATION_ANY])\n",
    "\n",
    "fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
    "size = (int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "videoWriter = cv2.VideoWriter(\n",
    "    'sources/MyOutputVid2.avi', cv2.VideoWriter_fourcc('I','4','2','0'), fps, size,\n",
    "    [cv2.VIDEOWRITER_PROP_HW_ACCELERATION, cv2.VIDEO_ACCELERATION_ANY])\n",
    "success, frame = videoCapture.read()\n",
    "while success: # Loop until there are no more frames.\n",
    "    videoWriter.write(frame)\n",
    "    success, frame = videoCapture.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ccb15a",
   "metadata": {},
   "source": [
    "Aquí, los parámetros indican a la instancia que utilice cualquier back-end de captura disponible con cualquier back-end de aceleración disponible. Del mismo modo, el parámetro indica a la instancia que utilice cualquier back-end de aceleración disponible.cv2.CAP_ANY, [cv2.CAP_PROP_HW_ACCELERATION, cv2.VIDEO_ACCELERATION_ANY]VideoCapture[cv2.VIDEOWRITER_PROP_HW_ACCELERATION, cv2.VIDEO_ACCELERATION_ANY]VideoWriter\n",
    "\n",
    "Actualmente, Windows es la plataforma mejor soportada, en términos del uso de OpenCV de codificación/decodificación acelerada por GPU. Algunas configuraciones de Linux también son compatibles. Un soporte más amplio puede estar disponible en futuras versiones de OpenCV 5.x. En sistemas donde OpenCV no admite codificación/decodificación acelerada por GPU, debería recurrir de forma segura a la codificación/decodificación de CPU. Tenga en cuenta que el soporte para la aceleración de GPU puede variar según el formato de video, así como el sistema operativo y el hardware.\n",
    "\n",
    "For more information on the ongoing efforts to support GPU-accelerated encoding/decoding, see the OpenCV Wiki article at https://github.com/opencv/opencv/wiki/Video-IO-hardware-acceleration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec39f99",
   "metadata": {},
   "source": [
    "# Capturing camera frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb71fca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cameraCapture = cv2.VideoCapture(2)\n",
    "print(cameraCapture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "fps = 30  # An assumption\n",
    "size = (int(cameraCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(cameraCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "size\n",
    "\n",
    "videoWriter = cv2.VideoWriter(\n",
    "    'sources/MyOutputVid.avi', cv2.VideoWriter_fourcc('I','4','2','0'),\n",
    "    fps, size)\n",
    "\n",
    "success, frame = cameraCapture.read()\n",
    "numFramesRemaining = 10 * fps - 1 # 10 seconds of frames\n",
    "while success and numFramesRemaining > 0:\n",
    "    videoWriter.write(frame)\n",
    "    success, frame = cameraCapture.read()\n",
    "    numFramesRemaining -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b858b35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cameraCapture0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m success0 \u001b[38;5;241m=\u001b[39m \u001b[43mcameraCapture0\u001b[49m\u001b[38;5;241m.\u001b[39mgrab()\n\u001b[0;32m      2\u001b[0m success1 \u001b[38;5;241m=\u001b[39m cameraCapture1\u001b[38;5;241m.\u001b[39mgrab()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success0 \u001b[38;5;129;01mand\u001b[39;00m success1:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cameraCapture0' is not defined"
     ]
    }
   ],
   "source": [
    "success0 = cameraCapture0.grab()\n",
    "success1 = cameraCapture1.grab()\n",
    "if success0 and success1:\n",
    "    frame0 = cameraCapture0.retrieve()\n",
    "    frame1 = cameraCapture1.retrieve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
