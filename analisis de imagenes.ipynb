{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc4515a",
   "metadata": {},
   "source": [
    "# Transformada de fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de40e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7465fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148 148 148 ...  84  72  97]\n",
      " [148 149 149 ...  99  98  82]\n",
      " [149 149 149 ...  97  84  31]\n",
      " ...\n",
      " [184 183 183 ... 179 191 200]\n",
      " [184 185 183 ... 192 187 190]\n",
      " [184 185 183 ... 198 191 191]]\n",
      "[[149 149 149 ...  77  76  76]\n",
      " [149 149 149 ...  76  75  75]\n",
      " [149 149 149 ...  73  73  72]\n",
      " ...\n",
      " [181 181 181 ... 186 193 196]\n",
      " [182 181 181 ... 183 191 193]\n",
      " [182 182 181 ... 182 190 192]]\n"
     ]
    }
   ],
   "source": [
    "kernel_3x3 = np.array([[-1, -1, -1],\n",
    "                       [-1, 8, -1],\n",
    "                       [-1, -1, -1]])\n",
    "\n",
    "kernel_5x5 = np.array([[-1, -1, -1, -1, -1],\n",
    "                       [-1, 1, 2, 1, -1],\n",
    "                       [-1, 2, 4, 2, -1],\n",
    "                       [-1, 1, 2, 1, -1],\n",
    "                       [-1, -1, -1, -1, -1]])\n",
    "\n",
    "img = cv2.imread(\"sources/estatua.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "k3 = ndimage.convolve(img, kernel_3x3) \n",
    "k5 = ndimage.convolve(img, kernel_5x5)\n",
    "\n",
    "blurred = cv2.GaussianBlur(img, (17,17), 0)\n",
    "\n",
    "g_hpf = img - blurred\n",
    "\n",
    "print(img)\n",
    "print(blurred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"k3\", k3)\n",
    "cv2.imshow(\"k5\", k5)\n",
    "cv2.imshow(\"blurred\", blurred)\n",
    "cv2.imshow(\"filtro\", g_hpf)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#cv2.waitKey()\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#k3 = ndimage.convolve(img, kernel_3x3) \n",
    "                 \n",
    "#k5 = ndimage.convolve(img, kernel_5x5)\n",
    "\n",
    "#blurred = cv2.GaussianBlur(img, (17,17), 0)\n",
    "#g_hpf = img - blurred\n",
    "\n",
    "#cv2.imshow(\"3x3\", k3)\n",
    "#cv2.imshow(\"5x5\", k5)\n",
    "#cv2.imshow(\"blurred\", blurred)\n",
    "#cv2.imshow(\"g_hpf\", g_hpf)\n",
    "#cv2.waitKey()\n",
    "#cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ed677",
   "metadata": {},
   "source": [
    "# Creating modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56caebc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola mundo Terricola\n",
      "Hola mundo Avicola\n",
      "Joder Avicola\n",
      "Joder Terricola\n"
     ]
    }
   ],
   "source": [
    "class saludar(object):\n",
    "    def __init__(self, nombreMundo):\n",
    "        self._nombreMundo = nombreMundo\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Joder {self._nombreMundo}\"\n",
    "        \n",
    "    def imprimir(self):\n",
    "        print(\"Hola mundo \" + self._nombreMundo)\n",
    "        \n",
    "\n",
    "x = saludar(\"Terricola\")\n",
    "y = saludar(\"Avicola\")\n",
    "\n",
    "x.imprimir()      \n",
    "y.imprimir()      \n",
    "\n",
    "print(y)\n",
    "print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f591b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "\n",
    "img = cv2.imread(\"sources/estatua.jpg\")\n",
    "\n",
    "#Aplicar un facot de borrosidad a la imagen\n",
    "#blurredSrc = cv2.medianBlur(img, 7)\n",
    "#graySrc = cv2.cvtColor(blurredSrc, cv2.COLOR_BGR2GRAY)     \n",
    "\n",
    "graySrc = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "cv2.Laplacian(graySrc, cv2.CV_8U, graySrc)  \n",
    "normalizedInverseAlpha = (1.0 / 255) * (255 - graySrc)\n",
    "\n",
    "cv2.imshow(\"sin filtro\", img)\n",
    "cv2.imshow(\"filtro1\", blurredSrc)\n",
    "cv2.imshow(\"filtro2\", graySrc)\n",
    "\n",
    "channels = cv2.split(img)\n",
    "cont = 0\n",
    "for channel in channels:\n",
    "    cont += 1\n",
    "    channel[:]= channel * normalizedInverseAlpha ##1.5\n",
    "    cv2.imshow(str(cont), channel)\n",
    "    \n",
    "\n",
    "nuevaImagen = cv2.merge(channels)\n",
    "cv2.imshow(\"nuevaImagen\", nuevaImagen)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "kernel = numpy.array([[-1, -1, -1],\n",
    "                      [-1,  10, -1],\n",
    "                      [-1, -1, -1]])\n",
    "\n",
    "\n",
    "nuevaImagen2 = cv2.filter2D(nuevaImagen, -1, kernel)\n",
    "\n",
    "cv2.imshow(\"nuevaImagen2\", nuevaImagen2)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124de138",
   "metadata": {},
   "source": [
    "# Detección de bordes con Canny\n",
    "\n",
    "OpenCV ofrece una práctica función llamada (por el inventor del algoritmo, John F. Canny), que es muy popular no solo por su efectividad, sino también por la simplicidad de su implementación en un programa OpenCV, ya que es una sola línea:Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a57a8527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"sources/estatua.jpg\", 0)\n",
    "cv2.imwrite(\"canny.jpg\", cv2.Canny(img, 200, 300))  # Canny in one line!\n",
    "cv2.imshow(\"canny\", cv2.imread(\"canny.jpg\"))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671aafe",
   "metadata": {},
   "source": [
    "# Detección de contornos\n",
    "\n",
    "Una tarea vital en la visión artificial es la detección de contornos. Queremos detectar contornos o contornos de sujetos contenidos en una imagen o cuadro de vídeo, no sólo como un fin en sí mismo, sino también como un paso hacia otras operaciones. Estas operaciones son, a saber, calcular polígonos delimitadores, aproximar formas y, en general, calcular regiones de interés (ROI). Los ROI simplifican considerablemente la interacción con los datos de imagen porque una región rectangular en NumPy se define fácilmente con un segmento de matriz. Utilizaremos mucho la detección de contornos y el ROI cuando exploremos los conceptos de detección de objetos (incluida la detección de rostros) y seguimiento de objetos en capítulos posteriores.\n",
    "\n",
    "Vamos a familiarizarnos con la API de detección de contornos a través de un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "334bdd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(array([[[ 50,  50]],\n",
      "\n",
      "       [[ 50, 149]],\n",
      "\n",
      "       [[149, 149]],\n",
      "\n",
      "       [[149,  50]]], dtype=int32),)\n",
      "[[[-1 -1 -1 -1]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.zeros((200,200), dtype=np.uint8)\n",
    "#print(img)\n",
    "img[50:150, 50:150] = 255\n",
    "print(img)\n",
    "\n",
    "cv2.imshow(\"contours\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#Encontrar puntos de mayor brillo\n",
    "ret, thresh = cv2.threshold(img, 127, 255, 0)\n",
    "\n",
    "#Encontrar contornos\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(contours)\n",
    "print(hierarchy)\n",
    "\n",
    "color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "img = cv2.drawContours(color, contours, -1, (0,255,255), 2)\n",
    "cv2.imshow(\"contours\", color)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb4158",
   "metadata": {},
   "source": [
    "Primero, creamos una imagen negra vacía que tiene un tamaño de 200 x 200 píxeles. Luego, colocamos un cuadrado blanco en el centro utilizando la capacidad de la matriz para asignar valores en una rebanada.\n",
    "\n",
    "Luego, fijamos el umbral de la imagen y llamamos a la función. Esta función tiene tres parámetros: la imagen de entrada, el tipo de jerarquía y el método de aproximación de contornos. El segundo parámetro especifica el tipo de árbol jerárquico devuelto por la función. Uno de los valores admitidos es , que indica a la función que recupere toda la jerarquía de contornos externos e internos. Estas relaciones pueden importar si estamos buscando objetos más pequeños (o regiones más pequeñas) dentro de objetos más grandes (o regiones más grandes). Si sólo desea recuperar la mayoría de los contornos externos, utilice . Esta puede ser una buena opción en los casos en que los objetos aparecen sobre un fondo plano y no nos importa encontrar objetos dentro de los objetos.findContourscv2.RETR_TREE cv2.RETR_EXTERNAL\n",
    "\n",
    "Volviendo al ejemplo de código, observe que la función devuelve dos elementos: los contornos y su jerarquía. Usamos los contornos para dibujar contornos verdes en la versión en color de la imagen. Finalmente, mostramos la imagen.findContours\n",
    "\n",
    "El resultado es un cuadrado blanco con su contorno dibujado en verde, ¡una escena espartana, pero efectiva para demostrar el concepto! Pasemos a ejemplos más significativos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e0e6a",
   "metadata": {},
   "source": [
    "# Detección de contornos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3fe0c4",
   "metadata": {},
   "source": [
    "\n",
    "Una tarea vital en la visión artificial es la detección de contornos. Queremos detectar contornos o contornos de sujetos contenidos en una imagen o cuadro de vídeo, no sólo como un fin en sí mismo, sino también como un paso hacia otras operaciones. Estas operaciones son, a saber, calcular polígonos delimitadores, aproximar formas y, en general, calcular regiones de interés (ROI). Los ROI simplifican considerablemente la interacción con los datos de imagen porque una región rectangular en NumPy se define fácilmente con un segmento de matriz. Utilizaremos mucho la detección de contornos y el ROI cuando exploremos los conceptos de detección de objetos (incluida la detección de rostros) y seguimiento de objetos en capítulos posteriores.\n",
    "\n",
    "Vamos a familiarizarnos con la API de detección de contornos a través de un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b36036cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.pyrDown(cv2.imread(\"sources/figura.jpg\"))\n",
    "ret, thresh = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), 100, 255, cv2.THRESH_BINARY)\n",
    "contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    #encuentre las coredenadas\n",
    "    x, y , w, h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h),(0, 255, 0), 2)\n",
    "    \n",
    "    #Encontrar area minima\n",
    "    rect = cv2.minAreaRect(c)\n",
    "    \n",
    "    #Clacular el area minimo de area del rectangulo\n",
    "    box=cv2.boxPoints(rect)\n",
    "    \n",
    "    #normalizar cordenadas a enteros\n",
    "    box = np.int0(box)\n",
    "\n",
    "    #dibiujar contornos\n",
    "    cv2.drawContours(img, [box], 0, (0, 0, 255), 3)\n",
    "    \n",
    "    #Calcular  centro y radio del circulo\n",
    "    \n",
    "    (x, y), radius = cv2.minEnclosingCircle(c)\n",
    "    \n",
    "    #Castear enteros\n",
    "    center = (int(x), int(y))\n",
    "    radius = int(radius)\n",
    "    \n",
    "    #draw the circle\n",
    "    img = cv2.circle(img, center, radius, (0, 255, 0), 2)\n",
    "    \n",
    "\n",
    "cv2.drawContours(img, contours, -1, (255, 0, 0), 1)\n",
    "cv2.imshow(\"contours\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d49b5e",
   "metadata": {},
   "source": [
    "# Contornos convexos y el algoritmo de Douglas-Peucker\n",
    "\n",
    "Cuando trabajamos con contornos, podemos encontrar sujetos con diversas formas, incluidas las convexas. Una forma convexa es aquella en la que no hay dos puntos dentro de esta forma cuya línea de conexión vaya fuera del perímetro de la forma misma.\n",
    "\n",
    "La primera facilidad que ofrece OpenCV para calcular el polígono delimitador aproximado de una forma es . El nombre de la función significa el algoritmo de Douglas-Peucker. Esta función toma tres parámetros:cv2.approxPolyDPDP\n",
    "\n",
    "\n",
    "Un contorno.\n",
    "Un valor épsilon que representa la discrepancia máxima entre el contorno original y el polígono aproximado (cuanto menor sea el valor, más cerca estará el valor aproximado del contorno original).\n",
    "Una bandera booleana. Si es , significa que el polígono está cerrado.True\n",
    "\n",
    "El valor épsilon es de vital importancia para obtener un contorno útil, así que entendamos lo que representa. Épsilon es la diferencia máxima entre el perímetro del polígono aproximado y el perímetro del contorno original. Cuanto menor sea esta diferencia, más similar será el polígono aproximado al contorno original.\n",
    "\n",
    "Puede que te preguntes por qué necesitamos un polígono aproximado cuando tenemos un contorno que ya es una representación precisa. La respuesta a esto es que un polígono es un conjunto de líneas rectas, y muchas tareas de visión artificial se vuelven más simples si podemos definir polígonos para que delimiten regiones para su posterior manipulación y procesamiento.\n",
    "\n",
    "Ahora que sabemos qué es un épsilon, necesitamos obtener información del perímetro de contorno como valor de referencia. Esto se puede obtener con la función de OpenCV:cv2.arcLength\n",
    "\n",
    "    epsilon = 0.01 * cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "\n",
    "Efectivamente, estamos instruyendo a OpenCV para calcular un polígono aproximado cuyo perímetro solo puede diferir del contorno original por una relación épsilon, específicamente, el 1% de la longitud del arco original.\n",
    "\n",
    "OpenCV también ofrece una función para obtener información de contorno procesada para formas convexas. Esta es una expresión directa de una línea:cv2.convexHull\n",
    "\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    \n",
    "Vamos a combinar el contorno original, el contorno poligonal aproximado y el casco convexo en una sola imagen para observar las diferencias entre ellos. Para simplificar las cosas, dibujaremos los contornos sobre un fondo negro para que el sujeto original no sea visible pero sus contornos sean:\n",
    "\n",
    "![imagen.png](attachment:imagen.png)\n",
    "\n",
    "\n",
    "Figura 3.4c: Resultados de la detección de contornos seguida de la detección de casco de contexto y aproximación de polígonos.\n",
    "Como puede ver, el casco convexo rodea todo el sujeto, el polígono aproximado es la forma de polígono más interno, y entre los dos está el contorno original, compuesto principalmente de arcos.\n",
    "\n",
    "Al combinar todos los pasos anteriores en un script que carga un archivo, encuentra contornos, aproxima los contornos como un polígono, encuentra un casco convexo y muestra una visualización, tenemos el siguiente código:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b07706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.pyrDown(cv2.imread(\"sources/figura.jpg\"))\n",
    "ret, thresh = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow(\"original\", img)\n",
    "cv2.imshow(\"thresh\", thresh)\n",
    "\n",
    "contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "black = np.zeros_like(img)\n",
    "\n",
    "for cnt in contours:\n",
    "    \n",
    "    epilson = 0.01 * cv2.arcLength(cnt, True)\n",
    "    #approx = cv2.approxPolyDP(cnt,epilson,True)\n",
    "    approx = cv2.approxPolyDP(cnt,epilson,True)\n",
    "\n",
    "    #rint(approx)\n",
    "    #hull = cv2.convexHull(cnt)\n",
    "    \n",
    "    cv2.drawContours(black, [cnt], -1, (255, 2, 0), 2)\n",
    "    cv2.drawContours(black, [approx], -1, (255, 255, 0), 2)\n",
    "    #cv2.drawContours(black, [hull], -1, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow(\"hull\", black)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a38e3e",
   "metadata": {},
   "source": [
    "# Detecting lines, circles, and other shapes\n",
    "\n",
    "Detectar bordes y encontrar contornos no solo son tareas comunes e importantes por derecho propio; También forman la base de otras operaciones complejas. La detección de líneas y formas camina de la mano con la detección de bordes y contornos, así que examinemos cómo OpenCV los implementa.\n",
    "\n",
    "La teoría detrás de la detección de líneas y formas tiene su fundamento en una técnica llamada transformada de Hough, inventada por Richard Duda y Peter Hart, quienes extendieron y generalizaron el trabajo realizado por Paul Hough a principios de la década de 1960. Echemos un vistazo a la API de OpenCV para transformaciones Hough.\n",
    "\n",
    "Detección de líneas\n",
    "En primer lugar, vamos a detectar algunas líneas. Podemos hacer esto con la función o la función. El primero usa la transformada de Hough estándar, mientras que el segundo usa la transformada de Hough probabilística (de ahí el en el nombre). La versión probabilística se llama así porque solo analiza un subconjunto de los puntos de la imagen y estima la probabilidad de que todos estos puntos pertenezcan a la misma línea. Esta implementación es una versión optimizada de la transformada estándar de Hough; Es menos intensivo computacionalmente y se ejecuta más rápido. se implementa de modo que devuelve los dos puntos finales de cada segmento de línea detectado, mientras que se implementa de modo que devuelve una representación de cada línea como un único punto y un ángulo, sin información sobre los puntos finales.HoughLinesHoughLinesPPHoughLinesPHoughLines\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=zbyn57jgWNg\n",
    "\n",
    "Echemos un vistazo a un ejemplo muy simple:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82a51ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"sources/tren.jpg\")\n",
    "gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Sacar los bordes, se hace sobre el gris para evitar ruidos molestos\n",
    "bordes = cv2.Canny(gris, 150, 255)\n",
    "\n",
    "#Sacar la lineas con algoritmo de HOUGH\n",
    "lineas = cv2.HoughLinesP(bordes,\n",
    "                        rho=1,\n",
    "                        theta=np.pi/180.0,\n",
    "                        threshold=20,\n",
    "                        minLineLength=80,\n",
    "                        maxLineGap=5)\n",
    "\n",
    "print(len(lineas))\n",
    "for linea in lineas:\n",
    "    x1, y1, x2, y2 = linea[0]\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"gris\", gris)\n",
    "cv2.imshow(\"bordes\", bordes)\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ee787",
   "metadata": {},
   "source": [
    "Una parte crucial de este script simple, como parte de la llamada a la función, es establecer la longitud de línea mínima (se descartarán las líneas más cortas) y el espacio de línea máximo, que es el tamaño máximo de un espacio en una línea antes de que los dos segmentos comiencen a considerarse como líneas separadas.HoughLines\n",
    "\n",
    "Además, tenga en cuenta que la función toma una imagen binaria de un solo canal, que se procesa a través del filtro de detección de bordes Canny. Canny no es un requisito estricto, pero una imagen que ha sido denoizada y solo representa bordes es la fuente ideal para una transformada de Hough, por lo que encontrará que esta es una práctica común.HoughLines\n",
    "\n",
    "Los parámetros de son los siguientes: HoughLinesP\n",
    "\n",
    "* La imagen binaria de Canny u otro filtro de detección de bordes.\n",
    "* La resolución o el tamaño de paso que se va a usar al buscar líneas ```rho```. es el tamaño del paso posicional en píxeles, mientras ```theta``` que es el tamaño del paso de rotación en radianes. Por ejemplo, si especificamos ```rho=1``` y ```theta=np.pi/180.0``` encontramos líneas que están separadas por tan solo 1 píxel y 1 grado.\n",
    "* El ```thresholdthreshold```, representa el umbral por debajo del cual se descarta una línea. La transformada de Hough funciona con un sistema de contenedores y votos, con cada contenedor representando una línea, por lo que si una línea candidata tiene al menos el número de votos del ```threshold```, se conserva; de lo contrario, se descarta.\n",
    "\n",
    "*  Un argumento opcional ```lines```, el cual no usamos aqui y que no representa realmente un usop masivo en la funcion de python, el argumento `lines` se puiede usar para proveer una nueva lista in la cual ```HoughLinesP```colocara el resultado de lineas; de otro lado este retornara una nueva lista\n",
    "\n",
    "* establece la longitud mínima de la línea (se descartarán las líneas más cortas) y la brecha de línea máxima, que es el tamaño máximo de una brecha en una línea antes de que los dos segmentos comiencen a considerarse como líneas separadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ccff73",
   "metadata": {},
   "source": [
    "# Detecting circles\n",
    "OpenCV también tiene una función para detectar círculos, llamada `HoughCircles`. Funciona de una manera muy similar a `HoughLines`, pero donde `minLineLength`y `maxLineGap`fueron los parámetros utilizados para descartar o retener líneas, `HoughCircles`en su lugar nos permite especificar una distancia mínima entre los centros de un círculo, así como valores mínimos y máximos para el radio de un círculo. Aquí está el ejemplo obligatorio:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c798bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "planetas = cv2.imread(\"sources/planetas.jpg\")\n",
    "gris =  cv2.cvtColor(planetas, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Suavizado de la imagen\n",
    "gris2 = cv2.medianBlur(gris, 9)\n",
    "\n",
    "#Sacar circulos\n",
    "circulos = cv2.HoughCircles(gris2, cv2.HOUGH_GRADIENT, 1, 80, param1=100, param2=25, minRadius=0, maxRadius=0)\n",
    "#print(circulos)\n",
    "\n",
    "#Redondear los parametros a entero\n",
    "circulos = np.uint16(np.around(circulos))\n",
    "#print(circulos)\n",
    "\n",
    "for i in circulos[0]:\n",
    "    #Desempaquetar los valores del frame\n",
    "    x, y, z = i\n",
    "    \n",
    "    #dibujar fuera del circulo\n",
    "    cv2.circle(planetas, (x, y), z, (0, 255, 0), 2)\n",
    "    \n",
    "    #Dibujar el centro del circulo, el argumento \"2\" entabla el radio\n",
    "    cv2.circle(planetas, (x, y), 2, (0, 0, 255), 3)\n",
    "\n",
    "cv2.imshow(\"imagenOriginal\", planetas)\n",
    "cv2.imshow(\"grises\", gris)\n",
    "cv2.imshow(\"grises2\", gris2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564ef6a",
   "metadata": {},
   "source": [
    "# Detecting other shapes\n",
    "\n",
    "Las implementaciones de OpenCV de la transformación de Hough se limitan a detectar líneas y círculos; Sin embargo, ya exploramos implícitamente la detección de formas en general cuando hablamos de `approxPolyDP`. Esta función permite la aproximación de polígonos, por lo que si su imagen contiene polígonos, se detectarán con precisión mediante el uso combinado de `cv2.findContours` y ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
