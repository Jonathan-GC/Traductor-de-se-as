{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2eea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950\n",
      "(798, 950, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"sources/emblema.jpg\")\n",
    "#img = cv2.imread(\"sources/Geeks.png\")\n",
    "img = cv2.imread(\"sources/caras.jpg\")\n",
    "\n",
    "print(len(img[0]))\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "img2 = cv2.resize(img,(900, 545), interpolation=cv2.INTER_BITS)\n",
    "\n",
    "gauss = cv2.GaussianBlur(img2,(5,5),3)\n",
    "\n",
    "\n",
    "hpf = img2 - gauss\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "cv2.imshow(\"hpf\", hpf)\n",
    "cv2.imshow(\"gaus\", gauss)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1caa04",
   "metadata": {},
   "source": [
    "# Conceptualizing Haar cascades\n",
    "\n",
    "Cuando hablamos de clasificar objetos y rastrear su ubicación, ¿qué es exactamente lo que esperamos identificar? ¿Qué constituye una parte reconocible de un objeto?\n",
    "\n",
    "Las imágenes fotográficas, incluso desde una cámara web, pueden contener muchos detalles para nuestro placer visual (humano). Sin embargo, el detalle de la imagen tiende a ser inestable con respecto a las variaciones en la iluminación, el ángulo de visión, la distancia de visión, el movimiento de la cámara y el ruido digital. Además, incluso las diferencias reales en los detalles físicos podrían no interesarnos para la clasificación. A Joseph Howse, uno de los autores de este libro, se le enseñó en la escuela que no hay dos copos de nieve iguales bajo un microscopio. Afortunadamente, cuando era un niño canadiense, ya había aprendido a reconocer copos de nieve sin un microscopio, ya que las similitudes son más obvias a granel.\n",
    "\n",
    "Por lo tanto, tener algunos medios para abstraer los detalles de la imagen es útil para producir resultados estables de clasificación y seguimiento. Las abstracciones se llaman características, que se dice que se extraen de los datos de la imagen. Debe haber muchas menos características que píxeles, aunque cualquier píxel puede influir en múltiples características. Un conjunto de entidades se representa como un vector (conceptualmente, un conjunto de coordenadas en un espacio multidimensional), y el nivel de similitud entre dos imágenes se puede evaluar en función de alguna medida de la distancia entre los vectores de características correspondientes de las imágenes.\n",
    "\n",
    "Más adelante, en el Capítulo 6, Recuperación de imágenes y búsqueda mediante descriptores de imágenes, exploraremos varios tipos de características, así como formas avanzadas de describir y hacer coincidir conjuntos de entidades.\n",
    "\n",
    "Las características similares a Haar son un tipo de característica que a menudo se aplica a la detección de rostros en tiempo real. Se utilizaron por primera vez para este propósito en el artículo Robust Real-Time Face Detection, de Paul Viola y Michael Jones (International Journal of Computer Vision 57 (2), 137-154, Kluwer Academic Publishers, 2001). Una versión electrónica de este documento está disponible en http://comp3204.ecs.soton.ac.uk/cw/viola04ijcv.pdf.\n",
    "\n",
    "Cada característica similar a Haar describe el patrón de contraste entre las regiones de imagen adyacentes. Por ejemplo, las aristas, los vértices y las líneas finas generan cada uno un tipo de entidad. Algunas características son distintivas en el sentido de que típicamente ocurren en una cierta clase de objeto (como una cara) pero no en otros objetos. Estas características distintivas se pueden organizar en una jerarquía, llamada cascada, en la que las capas más altas contienen características de mayor distinción, lo que permite a un clasificador rechazar rápidamente los sujetos que carecen de estas características. Si un sujeto es una buena combinación para las características de la capa superior, entonces el clasificador también considera las características de la capa inferior para eliminar más falsos positivos.\n",
    "\n",
    "Para cualquier sujeto dado, las características pueden variar dependiendo de la escala de la imagen y el tamaño del vecindario (la región de píxeles cercanos) en el que se evalúa el contraste. El tamaño del vecindario se llama tamaño de ventana. Para hacer que un clasificador en cascada de Haar sea invariante de escala o, en otras palabras, robusto a los cambios de escala, el tamaño de la ventana se mantiene constante, pero las imágenes se reescalan varias veces; Por lo tanto, en algún nivel de reescalado, el tamaño de un objeto (como una cara) puede coincidir con el tamaño de la ventana. Juntas, la imagen original y las imágenes reescaladas se denominan pirámide de imágenes, y cada nivel sucesivo en esta pirámide es una imagen reescalada más pequeña. OpenCV proporciona un clasificador invariante de escala que puede cargar una cascada de Haar desde un archivo XML en un formato determinado. Internamente, este clasificador convierte cualquier imagen dada en una pirámide de imágenes.\n",
    "\n",
    "Las cascadas de Haar, tal como se implementan en OpenCV, no son robustas a los cambios en la rotación o la perspectiva. Por ejemplo, una cara al revés no se considera similar a una cara erguida y una cara vista de perfil no se considera similar a una cara vista desde el frente. Una implementación más compleja e intensiva en recursos podría mejorar la robustez de una cascada de Haar a la rotación al considerar múltiples transformaciones de imágenes, así como múltiples tamaños de ventana. Sin embargo, nos limitaremos a la implementación en OpenCV.\n",
    "\n",
    "\n",
    "## Obtención de datos en cascada de Haar\n",
    "\n",
    "La instalación de OpenCV 5 debe contener una subcarpeta llamada . La ruta a esta carpeta se almacena en una variable OpenCV denominada . `datacv2.data.haarcascades`\n",
    "\n",
    "La carpeta contiene archivos XML que pueden ser cargados por una clase OpenCV llamada . Una instancia de esta clase interpreta un archivo XML determinado como una cascada de Haar, que proporciona un modelo de detección para un tipo de objeto, como una cara. Puede detectar este tipo de objeto en cualquier imagen. Como de costumbre, podríamos obtener una imagen fija de un archivo, o podríamos obtener una serie de fotogramas de un archivo de video o una cámara de video. `datacv2.CascadeClassifiercv2.CascadeClassifier`\n",
    "\n",
    "Desde la carpeta, usaremos los siguientes archivos en cascada: `data`\n",
    "\n",
    "\n",
    "`\n",
    "haarcascade_frontalface_default.xml\n",
    "haarcascade_eye.xml\n",
    "`\n",
    "\n",
    "Como sus nombres sugieren, estas cascadas son para detectar rostros y ojos. Requieren una visión frontal y vertical del sujeto. Los usaremos más adelante cuando construyamos un detector facial.\n",
    "\n",
    "Si tienes curiosidad sobre cómo se generan estos archivos en cascada, puedes encontrar más información en el libro de Joseph Howse, OpenCV 4 for Secret Agents (Packt Publishing, 2019), específicamente en el Capítulo 3, Entrenando una alarma inteligente para reconocer al villano y su gato. Con mucha paciencia y una computadora razonablemente potente, puede hacer sus propias cascadas y entrenarlas para varios tipos de objetos.\n",
    "\n",
    "\n",
    "## Uso de OpenCV para realizar la detección de rostros\n",
    "hay poca diferencia `cv2.CascadeClassifier` si realizamos la detección de rostros en una imagen fija o en una transmisión de video. El último es solo una versión secuencial del primero: la detección de rostros en un video es simplemente detección de rostros aplicada a cada cuadro. Naturalmente, con técnicas más avanzadas, sería posible rastrear una cara detectada continuamente a través de múltiples cuadros y determinar que la cara es la misma en cada cuadro. Sin embargo, es bueno saber que un enfoque secuencial básico también funciona.\n",
    "\n",
    "Sigamos adelante y detectemos algunas caras.\n",
    "\n",
    "### Realización de la detección de rostros en una imagen fija\n",
    "La primera y más básica forma de realizar la detección de rostros es cargar una imagen y detectar rostros en ella. Para que el resultado sea visualmente significativo, dibujaremos rectángulos alrededor de las caras en la imagen original. Recordando que el detector de rostros está diseñado para caras verticales y frontales, usaremos una imagen de una fila de personas, específicamente leñadores, de pie hombro con hombro y mirando hacia el fotógrafo o espectador.\n",
    "\n",
    "Sigamos adelante y creemos el siguiente script básico para realizar la detección de rostros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3ba166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JONATHAN GONZALEZ\\AppData\\Roaming\\Python\\Python39\\site-packages\\cv2\\data\\\n",
      "[[[252 252 252]\n",
      "  [252 252 252]\n",
      "  [252 252 252]\n",
      "  ...\n",
      "  [ 66  70 119]\n",
      "  [ 58  70 106]\n",
      "  [ 64  76 118]]\n",
      "\n",
      " [[252 252 252]\n",
      "  [252 252 252]\n",
      "  [252 252 252]\n",
      "  ...\n",
      "  [ 57  59  99]\n",
      "  [ 56  65  98]\n",
      "  [ 57  67 107]]\n",
      "\n",
      " [[252 252 252]\n",
      "  [252 252 252]\n",
      "  [252 252 252]\n",
      "  ...\n",
      "  [ 45  46  80]\n",
      "  [ 55  60  93]\n",
      "  [ 57  60 105]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 45  44  53]\n",
      "  [ 45  44  53]\n",
      "  [ 45  44  54]\n",
      "  ...\n",
      "  [190 192 202]\n",
      "  [191 194 202]\n",
      "  [189 191 201]]\n",
      "\n",
      " [[ 44  43  52]\n",
      "  [ 44  43  52]\n",
      "  [ 45  44  53]\n",
      "  ...\n",
      "  [186 188 198]\n",
      "  [187 190 198]\n",
      "  [187 189 199]]\n",
      "\n",
      " [[ 41  43  51]\n",
      "  [ 41  42  52]\n",
      "  [ 42  43  53]\n",
      "  ...\n",
      "  [181 186 195]\n",
      "  [183 186 194]\n",
      "  [184 186 196]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier(f'{cv2.data.haarcascades}haarcascade_frontalface_default.xml')\n",
    "print(cv2.data.haarcascades)\n",
    "\n",
    "img = cv2.imread(\"sources/caras.jpg\")\n",
    "\n",
    "print(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
